{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GridSearch NN IRNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMo4st7Mgp9YVhtnlYlfaq2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidTatis/HyperParameter-Tunning/blob/main/GridSearch_NN_IRNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Libreries"
      ],
      "metadata": {
        "id": "RqlnUGwHT_Gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras[tensorflow]\n",
        "!pip install scikeras[tensorflow-cpu]"
      ],
      "metadata": {
        "id": "8KT8gmAwFwHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIF9UubTT5sy"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import matplotlib.pyplot as plt # plotting library\n",
        "%matplotlib inline\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense , Activation, Dropout,BatchNormalization,Input\n",
        "from tensorflow.keras.optimizers import Adam ,RMSprop\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import  backend as K\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "from google.colab import drive\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Lambda, BatchNormalization\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D, Input,concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset"
      ],
      "metadata": {
        "id": "MQSFAbAdUHj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_X = genfromtxt(\"/content/drive/My Drive/AI datasets/elements/train_X.csv\", delimiter=',')\n",
        "train_y = genfromtxt(\"/content/drive/My Drive/AI datasets/elements/train_Y.csv\", delimiter=',')\n",
        "valid_X = genfromtxt(\"/content/drive/My Drive/AI datasets/elements/valid_X.csv\", delimiter=',')\n",
        "valid_y = genfromtxt(\"/content/drive/My Drive/AI datasets/elements/valid_y.csv\", delimiter=',')\n",
        "test_X = genfromtxt(\"/content/drive/My Drive/AI datasets/elements/test_X.csv\", delimiter=',')\n",
        "test_y = genfromtxt(\"/content/drive/My Drive/AI datasets/elements/test_y.csv\", delimiter=',')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL1-0AKdUJFb",
        "outputId": "62853d4e-4f80-4a60-9652-9f18435cc5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#num_layers refers to the layers in each block of the network. See models summary to clarify\n",
        "def irnet_model(num_layers,units,units_decrease,activation_function,optimizer):\n",
        "\n",
        "    input_vec = Input(shape=(86,))\n",
        "    x1=Activation(activation_function)(BatchNormalization()(Dense(units)(input_vec)))\n",
        "    m1=concatenate([input_vec, x1], axis=-1)\n",
        "    for layer in range(num_layers-1):\n",
        "      x1=Activation('relu')(BatchNormalization()(Dense(units)(m1)))\n",
        "      m1=concatenate([m1, x1], axis=-1)\n",
        "    \n",
        "    \n",
        "    units=int(units/units_decrease)\n",
        "    \n",
        "    x2=Activation(activation_function)(BatchNormalization()(Dense(units)(m1)))\n",
        "    m2=concatenate([m1, x2], axis=-1)\n",
        "    for layer in range(num_layers-1):\n",
        "      x2=Activation(activation_function)(BatchNormalization()(Dense(units)(m2)))\n",
        "      m2=concatenate([m2, x2], axis=-1)\n",
        "    \n",
        "    units=int(units/units_decrease)\n",
        "      \n",
        "    x3=Activation(activation_function)(BatchNormalization()(Dense(units)(m2)))\n",
        "    m3=concatenate([m2, x3], axis=-1)\n",
        "    for layer in range(num_layers-1):\n",
        "      x3=Activation(activation_function)(BatchNormalization()(Dense(units)(m3)))\n",
        "      m3=concatenate([m3, x3], axis=-1)\n",
        "    \n",
        "\n",
        "    x4=Activation(activation_function)(BatchNormalization()(Dense(64)(m3)))\n",
        "    m4=concatenate([m3, x4], axis=-1)\n",
        "    x5=Activation(activation_function)(BatchNormalization()(Dense(32)(m4)))\n",
        "    \n",
        "    \n",
        "    m5=concatenate([m4, x5], axis=-1)\n",
        "    x6=Dense(1,activation='linear')(m5)\n",
        "    \n",
        "    model=Model(input_vec,x6)\n",
        "    model.summary()\n",
        "    if(optimizer.lower()=='adam'):\n",
        "      model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "        loss=tf.keras.losses.mean_absolute_error,\n",
        "        metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "    elif(optimizer.lower()=='sgd'):\n",
        "       model.compile(\n",
        "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001,momentum=0.9),\n",
        "        loss=tf.keras.losses.mean_absolute_error,\n",
        "        metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "    plot_model(model,to_file='model.png')\n",
        "    return model"
      ],
      "metadata": {
        "id": "tKsz27QTURG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Cross Validation"
      ],
      "metadata": {
        "id": "hRHJ69Rgf7fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_folds=10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=1234)\n",
        "train_Xi=[[] for each in range(k_folds)]\n",
        "train_Yi=[[] for each in range(k_folds)]\n",
        "valid_Xi=[[] for each in range(k_folds)]\n",
        "valid_Yi=[[] for each in range(k_folds)]\n",
        "i=0\n",
        "\n",
        "for train_index, val_index in kf.split(train_X):\n",
        "    train_Xi[i] = pd.DataFrame(train_X).iloc[train_index,]\n",
        "    train_Yi[i] = pd.DataFrame(train_y).iloc[train_index,]\n",
        "    \n",
        "    valid_Xi[i]= pd.DataFrame(train_X).iloc[val_index,]\n",
        "    valid_Yi[i]= pd.DataFrame(train_y).iloc[val_index,]\n",
        "\n",
        "    i=i+1"
      ],
      "metadata": {
        "id": "QXWdNOQXf6yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=0 #for tests and development porpose im using only the fold 0.\n",
        "irnet_model=irnet_model(num_layers=1,units=2048,units_decrease=2,activation_function='relu',optimizer='adam')\n",
        "batch_size=16"
      ],
      "metadata": {
        "id": "qDXLkkGOgLcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "model = KerasClassifier(build_fn=irnet_model,epochs=10, batch_size=batch_size, verbose=0,\n",
        "                        num_layers=1,units=2048,units_decrease=2,activation_function='relu',optimizer='adam')\n",
        "# define the grid search parameters\n",
        "num_layers = [2,3,4]\n",
        "units_decrease = [2,4]\n",
        "activation_function=['relu','tanh']\n",
        "optimizer=['adam']\n",
        "units=[2048,1024]\n",
        "param_grid = dict(num_layers=num_layers,units_decrease=units_decrease,activation_function=activation_function,optimizer=optimizer,units=units)\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(train_Xi[i], train_Yi[i]) #TODO currently a memory when fitting (searching in google, its related to a version of Tensorflow)\n"
      ],
      "metadata": {
        "id": "nW0Gbg2MVeLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s7s_aezqYdJ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}